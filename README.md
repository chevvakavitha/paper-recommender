# ğŸ“š Paper Recommender
*A semantic research paper recommendation system using transformer embeddings and FAISS vector search.*

<p align="center">
  <img src="assets/banner.png" width="100%" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge" />
  <img src="https://img.shields.io/badge/FAISS-Vector_Search-orange?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Transformers-Embeddings-green?style=for-the-badge" />
  <img src="https://img.shields.io/badge/Streamlit-UI-red?style=for-the-badge" />
</p>

---

## ğŸ“‘ Table of Contents
- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Architecture](#architecture)
- [Dataset](#dataset)
- [Installation](#installation)
- [Usage](#usage)
- [Future Improvements](#future-improvements)
- [Contact](#contact)

---

## ğŸŒŸ Overview
The **Paper Recommender** helps users discover relevant research papers using semantic embeddings instead of simple text matching.

It uses:
- ğŸ§  Sentence Transformer embeddings  
- âš¡ FAISS vector index for fast similarity search  
- ğŸ—‚ Metadata filtering (year, author, keywords)  
- ğŸ— Clean modular architecture  

This project is useful for:
- Researchers  
- Students  
- Literature review writers  
- Anyone working with academic data  

---

## ğŸš€ Features

### ğŸ” Semantic Search
High-quality semantic matching using Transformer embeddings.

### âš¡ FAISS Vector Index
Efficient KNN search across thousands of embeddings.

### ğŸ§  Transformer Embeddings
Uses:  
```
sentence-transformers/all-MiniLM-L6-v2
```

### ğŸ› Metadata Filters
Filter by:
- Author  
- Year  
- Keywords  

### ğŸ§± Modular Architecture
Clean folder structure for maintainability.

---

## ğŸ—‚ Project Structure

```
paper-recommender/
â”‚â”€â”€ app/                        # (Optional) Streamlit UI 
â”‚â”€â”€ assets/                     # Banner / screenshots
â”‚â”€â”€ data/                       # Ignored (large datasets)
â”‚â”€â”€ docs/                       # Additional documentation
â”‚â”€â”€ models/                     # Trained models (ignored)
â”‚â”€â”€ notebooks/                  # EDA & experimentation
â”‚â”€â”€ src/                        
â”‚   â”‚â”€â”€ app.py                  # Core app
â”‚   â”‚â”€â”€ preprocess.py           # Cleaning & normalization
â”‚   â”‚â”€â”€ pdf_utils.py            # PDF-to-text utilities
â”‚   â”‚â”€â”€ embed_index.py          # Embeddings + FAISS index builder
â”‚   â”‚â”€â”€ search.py               # Search logic
â”‚â”€â”€ tools/
â”‚   â”‚â”€â”€ test_search.py          # Unit test
â”‚â”€â”€ main.py                     # CLI entry point
â”‚â”€â”€ requirements.txt            # Dependencies
â”‚â”€â”€ README.md                   # Documentation
â”‚â”€â”€ .gitignore                  # Ignore large folders
```

---

## ğŸ§  Architecture

```
User Query
     â†“
Preprocessing
     â†“
Sentence Transformer (Embeddings)
     â†“
FAISS Index (Top-K Search)
     â†“
Metadata Filtering Layer
     â†“
Final Ranked Papers
```

---

## ğŸ“¥ Dataset

âš ï¸ The dataset exceeds GitHub's 100MB limit.

Download it manually:

```
<ADD_YOUR_GOOGLE_DRIVE_LINK_HERE>
```

Place the dataset in:

```
paper-recommender/data/
```

---

## ğŸ›  Installation

### 1ï¸âƒ£ Create Virtual Environment
```
python -m venv .venv
```

### 2ï¸âƒ£ Activate Environment  
**Windows:**
```
.venv\Scripts\activate
```
**Mac/Linux:**
```
source .venv/bin/activate
```

### 3ï¸âƒ£ Install Requirements
```
pip install -r requirements.txt
```

---

## â–¶ï¸ Usage

### CLI Version:
```
python main.py
```

### Streamlit UI:
```
streamlit run app/streamlit_app.py
```

### Example:
```python
from src.search import PaperSearch

searcher = PaperSearch(
    embedding_path="data/papers_embeddings_meta.parquet",
    metadata_path="data/papers_metadata.csv",
    faiss_index_path="data/faiss_index.bin"
)

results = searcher.get_similar_papers("neural networks for healthcare")
print(results.head())
```

---

## ğŸ“Œ Future Improvements
- Full Streamlit dashboard  
- Topic modeling integration  
- PDF upload + automatic embedding  
- Deploy using FastAPI  
- Add SHAP explanations  

---

## ğŸ“¬ Contact
**Cheva Kavitha**  
ğŸ“§ Email: kavithachevvakavitha@gmail.com  
ğŸ”— LinkedIn: www.linkedin.com/in/cheva-kavitha 

â­ If this project helped you, please give it a **star**!






