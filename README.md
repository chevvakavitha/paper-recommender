ğŸ“š Paper Recommender

A semantic research paper recommendation system using transformer embeddings and FAISS vector search.

<p align="center"> <img src="https://img.shields.io/badge/Python-3.10+-blue?style=for-the-badge" /> <img src="https://img.shields.io/badge/FAISS-Vector_Search-orange?style=for-the-badge" /> <img src="https://img.shields.io/badge/Transformers-Embeddings-green?style=for-the-badge" /> <img src="https://img.shields.io/badge/Streamlit-UI-red?style=for-the-badge" /> </p>

ğŸ“‘ Table of Contents
Overview
Features
Project Structure
Architecture
Dataset
Installation
Usage
Future Improvements
Contact

ğŸŒŸ Overview
The Paper Recommender helps users discover research papers based on semantic similarity rather than simple keywords.
It uses:
ğŸ§  Sentence Transformer embeddings
âš¡ FAISS vector index for fast similarity search
ğŸ—‚ Metadata filtering (year, author, keywords)
ğŸ— Modular & clean architecture

Ideal for:
Students
Researchers
Literature review writers
Anyone exploring academic content

ğŸš€ Features
ğŸ” Semantic Search
Find meaningful similar papers using transformer-based sentence embeddings.
âš¡ FAISS Vector Index
Fast KNN search over thousands of embeddings.
ğŸ§  Transformer Embeddings
Uses models like:
sentence-transformers/all-MiniLM-L6-v2
ğŸ§± Modular Architecture
Separated into src/, data/, tools/, models/.

ğŸ› Metadata Filters
Filter by:
Author
Year
Keywords

ğŸ—‚ Project Structure
paper-recommender/
â”‚â”€â”€ app/                        # (Optional) Streamlit UI 
â”‚â”€â”€ assets/                     # Banner / screenshots
â”‚â”€â”€ data/                       # Ignored (large datasets)
â”‚â”€â”€ docs/                       # Additional documentation
â”‚â”€â”€ models/                     # Trained models (ignored)
â”‚â”€â”€ notebooks/                  # EDA & experimentation
â”‚â”€â”€ src/                        
â”‚   â”‚â”€â”€ app.py                  # Core application logic
â”‚   â”‚â”€â”€ preprocess.py           # Cleaning & normalization
â”‚   â”‚â”€â”€ pdf_utils.py            # Optional PDF-to-text
â”‚   â”‚â”€â”€ embed_index.py          # Build embeddings & FAISS index
â”‚   â”‚â”€â”€ search.py               # Main search functions
â”‚â”€â”€ tools/
â”‚   â”‚â”€â”€ test_search.py          # Unit tests
â”‚â”€â”€ main.py                     # CLI entry point
â”‚â”€â”€ requirements.txt            # Dependencies
â”‚â”€â”€ README.md                   # Documentation
â”‚â”€â”€ .gitignore                  # Ignoring large folders

ğŸ§  Architecture
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚     User Query        â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                     Preprocessing Module
                              â†“
              Sentence Transformer Model
                   (Embeddings Generation)
                              â†“
                       FAISS Index
                 (Top-K Vector Search)
                              â†“
                  Metadata Filtering Layer
                              â†“
               Final Ranked Paper Results

ğŸ“¥ Dataset
âš ï¸ GitHub blocks files bigger than 100 MB, so the dataset is stored externally.
After download, place the files in:
paper-recommender/data/

ğŸ›  Installation
1ï¸âƒ£ Create Virtual Environment
python -m venv .venv
2ï¸âƒ£ Activate Environment
Windows
.venv\Scripts\activate
Mac/Linux
source .venv/bin/activate
3ï¸âƒ£ Install Requirements
pip install -r requirements.txt
â–¶ï¸ Usage
Run CLI version:
python main.py
Run Streamlit UI (Optional):
streamlit run app/streamlit_app.py

Minimal Python Example:
from src.search import PaperSearch

searcher = PaperSearch(
    embedding_path="data/papers_embeddings_meta.parquet",
    metadata_path="data/papers_metadata.csv",
    faiss_index_path="data/faiss_index.bin"
)

results = searcher.get_similar_papers("neural networks for healthcare")
print(results.head())

ğŸ“Œ Future Improvements
ğŸ“„ PDF upload + automatic embedding
ğŸŒ Full Streamlit dashboard
ğŸ” Add keyword extraction & topic modeling
ğŸ§  Explain recommendations using SHAP
â˜ï¸ Deploy as FastAPI web service
ğŸ§ª Add proper unit tests

ğŸ“¬ Contact

Cheva Kavitha
ğŸ“§ Email:  kavithachevvakavitha@gmail.com
ğŸ”— LinkedIn:  www.linkedin.com/in/cheva-kavitha

â­ If you like this project, consider giving it a star on GitHub!



